{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
    "# !unzip -q kagglecatsanddogs_3367a.zip\n",
    "# !ls PetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23410 files belonging to 2 classes.\n",
      "Using 18728 files for training.\n",
      "Found 23410 files belonging to 2 classes.\n",
      "Using 4682 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (32, 32)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(scale=1/255.),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes, dual=False):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        if dual:\n",
    "            x = layers.concatenate([layers.MaxPooling2D(3, strides=2, padding=\"same\")(x),\n",
    "                                    layers.AveragePooling2D(3, strides=2, padding=\"same\")(x)])\n",
    "            residual = layers.Conv2D(size*2, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        else:\n",
    "            x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "            residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "                previous_block_activation\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Project residual\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 47s 80ms/step - loss: 0.6594 - accuracy: 0.6327 - val_loss: 0.7634 - val_accuracy: 0.4957\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5987 - accuracy: 0.7053 - val_loss: 0.9052 - val_accuracy: 0.5043\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5702 - accuracy: 0.7368 - val_loss: 1.8540 - val_accuracy: 0.5043\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5511 - accuracy: 0.7558 - val_loss: 4.1670 - val_accuracy: 0.4957\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5455 - accuracy: 0.7605 - val_loss: 1.5176 - val_accuracy: 0.4957\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5317 - accuracy: 0.7735 - val_loss: 3.3401 - val_accuracy: 0.4957\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.5201 - accuracy: 0.7840 - val_loss: 1.7524 - val_accuracy: 0.4957\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5137 - accuracy: 0.7886 - val_loss: 1.7718 - val_accuracy: 0.4957\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.5037 - accuracy: 0.7947 - val_loss: 3.2739 - val_accuracy: 0.4957\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 45s 78ms/step - loss: 0.4952 - accuracy: 0.8012 - val_loss: 9.0184 - val_accuracy: 0.4957\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.4896 - accuracy: 0.8077 - val_loss: 4.5864 - val_accuracy: 0.4957\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.4835 - accuracy: 0.8116 - val_loss: 3.2699 - val_accuracy: 0.4957\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.4757 - accuracy: 0.8173 - val_loss: 1.5059 - val_accuracy: 0.4957\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.4709 - accuracy: 0.8211 - val_loss: 6.9389 - val_accuracy: 0.4957\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.4653 - accuracy: 0.8221 - val_loss: 1.1798 - val_accuracy: 0.4957\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.4607 - accuracy: 0.8283 - val_loss: 1.6467 - val_accuracy: 0.4957\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.4552 - accuracy: 0.8307 - val_loss: 3.4300 - val_accuracy: 0.4957\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 45s 78ms/step - loss: 0.4504 - accuracy: 0.8358 - val_loss: 2.6008 - val_accuracy: 0.4957\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 45s 77ms/step - loss: 0.4481 - accuracy: 0.8375 - val_loss: 2.9391 - val_accuracy: 0.4957\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.4489 - accuracy: 0.8395 - val_loss: 2.6474 - val_accuracy: 0.4957\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.4416 - accuracy: 0.8433 - val_loss: 2.1029 - val_accuracy: 0.4957\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.4356 - accuracy: 0.8435 - val_loss: 4.5313 - val_accuracy: 0.4957\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.4346 - accuracy: 0.8468 - val_loss: 1.7170 - val_accuracy: 0.4957\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 46s 79ms/step - loss: 0.4304 - accuracy: 0.8532 - val_loss: 1.8536 - val_accuracy: 0.4957\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 45s 78ms/step - loss: 0.4210 - accuracy: 0.8543 - val_loss: 1.9355 - val_accuracy: 0.4957\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 45s 78ms/step - loss: 0.4240 - accuracy: 0.8564 - val_loss: 3.2497 - val_accuracy: 0.4957\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 46s 79ms/step - loss: 0.4157 - accuracy: 0.8612 - val_loss: 3.3207 - val_accuracy: 0.4957\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4168 - accuracy: 0.8583 - val_loss: 1.5608 - val_accuracy: 0.4957\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.4110 - accuracy: 0.8644 - val_loss: 3.0214 - val_accuracy: 0.4957\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.4086 - accuracy: 0.8646 - val_loss: 1.7437 - val_accuracy: 0.4957\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.4033 - accuracy: 0.8713 - val_loss: 2.0873 - val_accuracy: 0.4957\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3972 - accuracy: 0.8718 - val_loss: 2.1905 - val_accuracy: 0.4957\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.4001 - accuracy: 0.8711 - val_loss: 1.9011 - val_accuracy: 0.4957\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3998 - accuracy: 0.8704 - val_loss: 1.0879 - val_accuracy: 0.4957\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3940 - accuracy: 0.8742 - val_loss: 1.1713 - val_accuracy: 0.4957\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3930 - accuracy: 0.8775 - val_loss: 0.7002 - val_accuracy: 0.4853\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.3865 - accuracy: 0.8819 - val_loss: 2.1988 - val_accuracy: 0.4957\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3860 - accuracy: 0.8813 - val_loss: 1.5818 - val_accuracy: 0.4957\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3846 - accuracy: 0.8828 - val_loss: 0.9555 - val_accuracy: 0.4966\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3853 - accuracy: 0.8831 - val_loss: 1.7025 - val_accuracy: 0.4957\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3799 - accuracy: 0.8855 - val_loss: 1.6267 - val_accuracy: 0.4957\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3762 - accuracy: 0.8866 - val_loss: 1.4812 - val_accuracy: 0.4957\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3722 - accuracy: 0.8921 - val_loss: 2.5337 - val_accuracy: 0.4957\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3726 - accuracy: 0.8915 - val_loss: 1.2264 - val_accuracy: 0.4957\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3714 - accuracy: 0.8931 - val_loss: 2.1010 - val_accuracy: 0.4957\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3708 - accuracy: 0.8926 - val_loss: 1.6362 - val_accuracy: 0.4957\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 47s 80ms/step - loss: 0.3641 - accuracy: 0.8950 - val_loss: 2.1052 - val_accuracy: 0.4957\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3636 - accuracy: 0.8968 - val_loss: 2.3574 - val_accuracy: 0.4957\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 47s 80ms/step - loss: 0.3578 - accuracy: 0.9007 - val_loss: 2.0139 - val_accuracy: 0.4957\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3612 - accuracy: 0.8966 - val_loss: 1.4159 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1468199a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2, dual=False)\n",
    "# keras.utils.plot_model(model, show_shapes=False)\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.6552 - accuracy: 0.6388 - val_loss: 0.6896 - val_accuracy: 0.5265\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.5689 - accuracy: 0.7132 - val_loss: 1.2457 - val_accuracy: 0.4957\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.5341 - accuracy: 0.7367 - val_loss: 0.7581 - val_accuracy: 0.4957\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.5112 - accuracy: 0.7563 - val_loss: 0.7029 - val_accuracy: 0.5019\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.4951 - accuracy: 0.7669 - val_loss: 3.3199 - val_accuracy: 0.4957\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.4835 - accuracy: 0.7727 - val_loss: 0.6880 - val_accuracy: 0.5446\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.4698 - accuracy: 0.7804 - val_loss: 0.8211 - val_accuracy: 0.5100\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4506 - accuracy: 0.7923 - val_loss: 1.8284 - val_accuracy: 0.4957\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4418 - accuracy: 0.7966 - val_loss: 7.5297 - val_accuracy: 0.4957\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.4355 - accuracy: 0.7978 - val_loss: 1.5306 - val_accuracy: 0.4957\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4221 - accuracy: 0.8077 - val_loss: 2.4382 - val_accuracy: 0.4957\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.4171 - accuracy: 0.8101 - val_loss: 0.8829 - val_accuracy: 0.4957\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4067 - accuracy: 0.8179 - val_loss: 4.4560 - val_accuracy: 0.4957\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3997 - accuracy: 0.8218 - val_loss: 2.0476 - val_accuracy: 0.4957\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3901 - accuracy: 0.8264 - val_loss: 2.7299 - val_accuracy: 0.4957\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3862 - accuracy: 0.8276 - val_loss: 1.2635 - val_accuracy: 0.4959\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3756 - accuracy: 0.8303 - val_loss: 5.1595 - val_accuracy: 0.4957\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3748 - accuracy: 0.8330 - val_loss: 4.3897 - val_accuracy: 0.4957\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3690 - accuracy: 0.8379 - val_loss: 3.4713 - val_accuracy: 0.4957\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3582 - accuracy: 0.8442 - val_loss: 3.9142 - val_accuracy: 0.4957\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3552 - accuracy: 0.8400 - val_loss: 1.3976 - val_accuracy: 0.4957\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3513 - accuracy: 0.8423 - val_loss: 1.6101 - val_accuracy: 0.4957\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3499 - accuracy: 0.8468 - val_loss: 1.2924 - val_accuracy: 0.4957\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3449 - accuracy: 0.8508 - val_loss: 2.9774 - val_accuracy: 0.4957\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3391 - accuracy: 0.8520 - val_loss: 1.0127 - val_accuracy: 0.4964\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3378 - accuracy: 0.8525 - val_loss: 0.6869 - val_accuracy: 0.5493\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3275 - accuracy: 0.8605 - val_loss: 1.8785 - val_accuracy: 0.4957\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3248 - accuracy: 0.8569 - val_loss: 11.7391 - val_accuracy: 0.4957\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3174 - accuracy: 0.8605 - val_loss: 3.3136 - val_accuracy: 0.4957\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3141 - accuracy: 0.8630 - val_loss: 2.5609 - val_accuracy: 0.4957\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3130 - accuracy: 0.8630 - val_loss: 1.8577 - val_accuracy: 0.4957\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3076 - accuracy: 0.8661 - val_loss: 5.9588 - val_accuracy: 0.4957\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3030 - accuracy: 0.8691 - val_loss: 15.5896 - val_accuracy: 0.4957\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.2993 - accuracy: 0.8705 - val_loss: 20.0956 - val_accuracy: 0.4957\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2936 - accuracy: 0.8761 - val_loss: 5.3613 - val_accuracy: 0.4957\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2896 - accuracy: 0.8744 - val_loss: 9.8318 - val_accuracy: 0.4957\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2897 - accuracy: 0.8778 - val_loss: 1.0305 - val_accuracy: 0.5011\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2875 - accuracy: 0.8764 - val_loss: 7.5514 - val_accuracy: 0.4957\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2763 - accuracy: 0.8815 - val_loss: 2.8182 - val_accuracy: 0.4957\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.2794 - accuracy: 0.8818 - val_loss: 3.5097 - val_accuracy: 0.4957\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.2743 - accuracy: 0.8818 - val_loss: 4.8408 - val_accuracy: 0.4957\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2727 - accuracy: 0.8842 - val_loss: 2.6492 - val_accuracy: 0.4962\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.2621 - accuracy: 0.8884 - val_loss: 1.0441 - val_accuracy: 0.5250\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.2634 - accuracy: 0.8895 - val_loss: 1.8463 - val_accuracy: 0.5006\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2612 - accuracy: 0.8883 - val_loss: 4.3010 - val_accuracy: 0.4957\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.2547 - accuracy: 0.8934 - val_loss: 5.1222 - val_accuracy: 0.4957\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2516 - accuracy: 0.8955 - val_loss: 5.0284 - val_accuracy: 0.4957\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 47s 80ms/step - loss: 0.2497 - accuracy: 0.8952 - val_loss: 5.2251 - val_accuracy: 0.4957\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.2468 - accuracy: 0.8965 - val_loss: 13.2237 - val_accuracy: 0.4957\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2461 - accuracy: 0.8956 - val_loss: 10.4824 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f146a68dc18>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2, dual=False)\n",
    "# keras.utils.plot_model(model, show_shapes=False)\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(label_smoothing=0.0),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 50s 85ms/step - loss: 0.6537 - accuracy: 0.6344 - val_loss: 0.6919 - val_accuracy: 0.5276\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.5661 - accuracy: 0.7113 - val_loss: 3.8972 - val_accuracy: 0.4957\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.5334 - accuracy: 0.7396 - val_loss: 2.6126 - val_accuracy: 0.4957\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.5105 - accuracy: 0.7533 - val_loss: 1.1532 - val_accuracy: 0.4957\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.4924 - accuracy: 0.7635 - val_loss: 6.7288 - val_accuracy: 0.4957\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4758 - accuracy: 0.7780 - val_loss: 1.7603 - val_accuracy: 0.4957\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.4621 - accuracy: 0.7880 - val_loss: 1.5380 - val_accuracy: 0.4957\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 50s 85ms/step - loss: 0.4538 - accuracy: 0.7883 - val_loss: 0.9512 - val_accuracy: 0.4957\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.4361 - accuracy: 0.7991 - val_loss: 1.9274 - val_accuracy: 0.4957\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.4295 - accuracy: 0.8036 - val_loss: 8.5278 - val_accuracy: 0.4957\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.4253 - accuracy: 0.8072 - val_loss: 0.9273 - val_accuracy: 0.4957\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4138 - accuracy: 0.8092 - val_loss: 3.5659 - val_accuracy: 0.4957\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.4096 - accuracy: 0.8107 - val_loss: 3.5734 - val_accuracy: 0.4957\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3977 - accuracy: 0.8203 - val_loss: 2.7209 - val_accuracy: 0.4957\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3958 - accuracy: 0.8178 - val_loss: 2.8406 - val_accuracy: 0.4957\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3847 - accuracy: 0.8297 - val_loss: 1.4104 - val_accuracy: 0.4957\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3772 - accuracy: 0.8293 - val_loss: 5.0395 - val_accuracy: 0.4957\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3747 - accuracy: 0.8311 - val_loss: 1.1059 - val_accuracy: 0.4957\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3724 - accuracy: 0.8347 - val_loss: 5.8966 - val_accuracy: 0.4957\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3673 - accuracy: 0.8368 - val_loss: 6.7865 - val_accuracy: 0.4957\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3591 - accuracy: 0.8431 - val_loss: 1.2589 - val_accuracy: 0.4957\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3545 - accuracy: 0.8435 - val_loss: 2.7149 - val_accuracy: 0.4957\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3464 - accuracy: 0.8484 - val_loss: 0.9797 - val_accuracy: 0.4957\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3430 - accuracy: 0.8478 - val_loss: 1.5797 - val_accuracy: 0.4957\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3284 - accuracy: 0.8577 - val_loss: 2.2370 - val_accuracy: 0.4957\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.3320 - accuracy: 0.8544 - val_loss: 3.5845 - val_accuracy: 0.4957\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3274 - accuracy: 0.8560 - val_loss: 1.1988 - val_accuracy: 0.5002\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3207 - accuracy: 0.8589 - val_loss: 1.2145 - val_accuracy: 0.4957\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3180 - accuracy: 0.8621 - val_loss: 8.0666 - val_accuracy: 0.4957\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3135 - accuracy: 0.8630 - val_loss: 3.7504 - val_accuracy: 0.4957\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3044 - accuracy: 0.8683 - val_loss: 1.1848 - val_accuracy: 0.4957\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3043 - accuracy: 0.8662 - val_loss: 1.0265 - val_accuracy: 0.4957\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3001 - accuracy: 0.8688 - val_loss: 2.4203 - val_accuracy: 0.4957\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3011 - accuracy: 0.8702 - val_loss: 0.9017 - val_accuracy: 0.4953\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2948 - accuracy: 0.8722 - val_loss: 2.8814 - val_accuracy: 0.4957\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2900 - accuracy: 0.8777 - val_loss: 3.2459 - val_accuracy: 0.4957\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2864 - accuracy: 0.8783 - val_loss: 2.4613 - val_accuracy: 0.4957\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.2842 - accuracy: 0.8767 - val_loss: 2.2463 - val_accuracy: 0.4957\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2768 - accuracy: 0.8835 - val_loss: 0.6955 - val_accuracy: 0.5844\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2705 - accuracy: 0.8851 - val_loss: 0.7108 - val_accuracy: 0.5942\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.2719 - accuracy: 0.8851 - val_loss: 1.5904 - val_accuracy: 0.4968\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2707 - accuracy: 0.8856 - val_loss: 3.2056 - val_accuracy: 0.4955\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2656 - accuracy: 0.8855 - val_loss: 10.2412 - val_accuracy: 0.4957\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2666 - accuracy: 0.8869 - val_loss: 4.0241 - val_accuracy: 0.4957\n",
      "Epoch 45/50\n",
      "178/586 [========>.....................] - ETA: 28s - loss: 0.2513 - accuracy: 0.8919"
     ]
    }
   ],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2, dual=False)\n",
    "# keras.utils.plot_model(model, show_shapes=False)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 49s 83ms/step - loss: 0.6486 - accuracy: 0.6382 - val_loss: 0.7411 - val_accuracy: 0.5043\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.5755 - accuracy: 0.7074 - val_loss: 0.7234 - val_accuracy: 0.5064\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.5364 - accuracy: 0.7377 - val_loss: 2.5416 - val_accuracy: 0.4957\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.5191 - accuracy: 0.7506 - val_loss: 0.7117 - val_accuracy: 0.5126\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4999 - accuracy: 0.7679 - val_loss: 1.0414 - val_accuracy: 0.4962\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.4851 - accuracy: 0.7760 - val_loss: 2.8568 - val_accuracy: 0.4957\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4730 - accuracy: 0.7827 - val_loss: 3.4902 - val_accuracy: 0.4957\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4596 - accuracy: 0.7907 - val_loss: 5.4135 - val_accuracy: 0.4957\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.4498 - accuracy: 0.7975 - val_loss: 2.6690 - val_accuracy: 0.4957\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4350 - accuracy: 0.8054 - val_loss: 6.5419 - val_accuracy: 0.4957\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4330 - accuracy: 0.8047 - val_loss: 3.4459 - val_accuracy: 0.4957\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.4268 - accuracy: 0.8135 - val_loss: 1.5065 - val_accuracy: 0.4957\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4182 - accuracy: 0.8131 - val_loss: 9.1546 - val_accuracy: 0.4957\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4071 - accuracy: 0.8217 - val_loss: 2.9836 - val_accuracy: 0.4957\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.4066 - accuracy: 0.8228 - val_loss: 2.2268 - val_accuracy: 0.4957\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.4000 - accuracy: 0.8231 - val_loss: 7.7291 - val_accuracy: 0.4957\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3961 - accuracy: 0.8297 - val_loss: 2.8778 - val_accuracy: 0.4957\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 3.5895 - val_accuracy: 0.4957\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3780 - accuracy: 0.8385 - val_loss: 4.0552 - val_accuracy: 0.4957\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3766 - accuracy: 0.8380 - val_loss: 1.3486 - val_accuracy: 0.4957\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3720 - accuracy: 0.8371 - val_loss: 0.8360 - val_accuracy: 0.5278\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3616 - accuracy: 0.8430 - val_loss: 3.6847 - val_accuracy: 0.4957\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3567 - accuracy: 0.8465 - val_loss: 1.9748 - val_accuracy: 0.4957\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3498 - accuracy: 0.8518 - val_loss: 4.1190 - val_accuracy: 0.4957\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.3517 - accuracy: 0.8535 - val_loss: 5.6195 - val_accuracy: 0.4957\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3482 - accuracy: 0.8552 - val_loss: 3.5289 - val_accuracy: 0.4957\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 49s 84ms/step - loss: 0.3371 - accuracy: 0.8574 - val_loss: 5.6084 - val_accuracy: 0.4957\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3358 - accuracy: 0.8590 - val_loss: 1.4362 - val_accuracy: 0.4957\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3304 - accuracy: 0.8611 - val_loss: 1.6545 - val_accuracy: 0.4957\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3332 - accuracy: 0.8620 - val_loss: 1.3255 - val_accuracy: 0.4957\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3274 - accuracy: 0.8622 - val_loss: 5.4602 - val_accuracy: 0.4957\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.3211 - accuracy: 0.8674 - val_loss: 1.0112 - val_accuracy: 0.4979\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3175 - accuracy: 0.8704 - val_loss: 1.1867 - val_accuracy: 0.4962\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.3129 - accuracy: 0.8729 - val_loss: 6.9864 - val_accuracy: 0.4957\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.3127 - accuracy: 0.8719 - val_loss: 2.4469 - val_accuracy: 0.4957\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3091 - accuracy: 0.8728 - val_loss: 2.4416 - val_accuracy: 0.4957\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.3019 - accuracy: 0.8767 - val_loss: 1.8851 - val_accuracy: 0.4957\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2991 - accuracy: 0.8789 - val_loss: 3.5840 - val_accuracy: 0.4957\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2931 - accuracy: 0.8803 - val_loss: 1.4097 - val_accuracy: 0.4957\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 47s 81ms/step - loss: 0.2959 - accuracy: 0.8786 - val_loss: 1.7207 - val_accuracy: 0.4957\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2941 - accuracy: 0.8783 - val_loss: 2.3619 - val_accuracy: 0.4957\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2896 - accuracy: 0.8837 - val_loss: 5.0584 - val_accuracy: 0.4957\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2846 - accuracy: 0.8847 - val_loss: 1.9868 - val_accuracy: 0.4957\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2801 - accuracy: 0.8896 - val_loss: 4.8491 - val_accuracy: 0.4957\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 48s 83ms/step - loss: 0.2771 - accuracy: 0.8917 - val_loss: 5.0910 - val_accuracy: 0.4957\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.2741 - accuracy: 0.8912 - val_loss: 4.0136 - val_accuracy: 0.4957\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2735 - accuracy: 0.8883 - val_loss: 5.3008 - val_accuracy: 0.4957\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 48s 81ms/step - loss: 0.2686 - accuracy: 0.8935 - val_loss: 3.3540 - val_accuracy: 0.4957\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 48s 82ms/step - loss: 0.2653 - accuracy: 0.8948 - val_loss: 1.8077 - val_accuracy: 0.4957\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 49s 83ms/step - loss: 0.2640 - accuracy: 0.8963 - val_loss: 3.2729 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13f8511048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2, dual=False)\n",
    "# keras.utils.plot_model(model, show_shapes=False)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"ls01_save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.BinaryCrossentropy(label_smoothing=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(var):\n",
    "    match = [k for k, v in globals().items() if v == var]\n",
    "    return match[0].replace('_history', '') if match else None\n",
    "\n",
    "def plot(metric, *history):\n",
    "    \n",
    "    getter = metric.replace('train_', '')\n",
    "    \n",
    "    for h in history:\n",
    "        plt.plot(h.history['{}'.format(getter)])\n",
    "    plt.title('{}, batch size: 32'.format(metric).upper())\n",
    "    plt.ylabel('{}'.format(metric))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(list(map(name, history)), loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9a7f1097e7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_history' is not defined"
     ]
    }
   ],
   "source": [
    "for metric in ['train_loss', 'val_loss', 'train_accuracy', 'val_accuracy']:\n",
    "    plot(metric, baseline_history, dual_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
