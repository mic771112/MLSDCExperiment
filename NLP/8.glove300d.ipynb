{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'jigsaw-toxic-comment-classification-challenge'\n",
    "train = pd.read_csv(f'{base_path}/train.csv')\n",
    "test = pd.read_csv(f'{base_path}/test.csv')\n",
    "submission = pd.read_csv(f'{base_path}/sample_submission.csv')\n",
    "test_labels = pd.read_csv(f'{base_path}/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = f'{base_path}/glove.6B.300d.txt'\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "with open(EMBEDDING_FILE) as f:\n",
    "    embeddings_index = dict(get_coefs(*o.strip().split()) for o in f)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean = all_embs.mean()\n",
    "emb_std = all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing (extract useful information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 30000\n",
    "MAX_SENTENSE_LEN = 100\n",
    "EMBEDDING_SIZE = all_embs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[\"comment_text\"].values\n",
    "y_train = train[LABELS].values\n",
    "x_test = test[\"comment_text\"].values\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=MAX_TOKENS)\n",
    "tokenizer.fit_on_texts(list(x_train) + list(x_test)) # is it a proper trick?\n",
    "\n",
    "x_train, x_test = map(tokenizer.texts_to_sequences, [x_train, x_test])\n",
    "x_train, x_test = map(lambda x: sequence.pad_sequences(x, maxlen=MAX_SENTENSE_LEN), [x_train, x_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_TOKENS, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, EMBEDDING_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_TOKENS: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding & visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-noise (no drop data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " 30000,\n",
       " 300,\n",
       " array([[-0.44480804, -0.28227118,  0.39783603, ..., -0.2178669 ,\n",
       "          0.30672413,  0.00205656],\n",
       "        [ 0.04656   ,  0.21318001, -0.0074364 , ...,  0.0090611 ,\n",
       "         -0.20988999,  0.053913  ],\n",
       "        [-0.25756001, -0.057132  , -0.67189997, ..., -0.16043   ,\n",
       "          0.046744  , -0.070621  ],\n",
       "        ...,\n",
       "        [-0.21454   , -0.52314001, -0.1452    , ...,  0.63898998,\n",
       "          0.38471001,  0.47398999],\n",
       "        [-0.18870001, -0.56199002, -0.026557  , ...,  0.16516   ,\n",
       "          0.091691  ,  0.55971998],\n",
       "        [ 0.25328001, -0.83880001, -0.59951001, ..., -0.39467999,\n",
       "          0.69099998,  0.82291001]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENTENSE_LEN, MAX_TOKENS, EMBEDDING_SIZE, embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 242s 408ms/step - loss: 9.3609 - acc: 0.7809 - val_loss: 6.4431 - val_acc: 0.9952\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 249s 420ms/step - loss: 4.6999 - acc: 0.9720 - val_loss: 3.3038 - val_acc: 0.9952\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 255s 430ms/step - loss: 2.4234 - acc: 0.9832 - val_loss: 1.7163 - val_acc: 0.9952\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 243s 411ms/step - loss: 1.2655 - acc: 0.9890 - val_loss: 0.9064 - val_acc: 0.9952\n",
      "Epoch 5/100\n",
      "593/593 [==============================] - 255s 430ms/step - loss: 0.6760 - acc: 0.9908 - val_loss: 0.4958 - val_acc: 0.9952\n",
      "Epoch 6/100\n",
      "593/593 [==============================] - 256s 431ms/step - loss: 0.3772 - acc: 0.9914 - val_loss: 0.2899 - val_acc: 0.9952\n",
      "Epoch 7/100\n",
      "593/593 [==============================] - 255s 431ms/step - loss: 0.2264 - acc: 0.9929 - val_loss: 0.1861 - val_acc: 0.9952\n",
      "Epoch 8/100\n",
      "593/593 [==============================] - 256s 432ms/step - loss: 0.1495 - acc: 0.9934 - val_loss: 0.1340 - val_acc: 0.9952\n",
      "Epoch 9/100\n",
      "593/593 [==============================] - 256s 431ms/step - loss: 0.1095 - acc: 0.9935 - val_loss: 0.1058 - val_acc: 0.9952\n",
      "Epoch 10/100\n",
      "593/593 [==============================] - 256s 431ms/step - loss: 0.0878 - acc: 0.9937 - val_loss: 0.0922 - val_acc: 0.9952\n",
      "Epoch 11/100\n",
      "593/593 [==============================] - 256s 432ms/step - loss: 0.0748 - acc: 0.9938 - val_loss: 0.0844 - val_acc: 0.9952\n",
      "Epoch 12/100\n",
      "593/593 [==============================] - 253s 427ms/step - loss: 0.0665 - acc: 0.9937 - val_loss: 0.0795 - val_acc: 0.9952\n",
      "Epoch 13/100\n",
      "593/593 [==============================] - 247s 417ms/step - loss: 0.0611 - acc: 0.9938 - val_loss: 0.0760 - val_acc: 0.9952\n",
      "Epoch 14/100\n",
      "593/593 [==============================] - 246s 415ms/step - loss: 0.0572 - acc: 0.9933 - val_loss: 0.0760 - val_acc: 0.9952\n",
      "Epoch 15/100\n",
      "593/593 [==============================] - 259s 437ms/step - loss: 0.0541 - acc: 0.9934 - val_loss: 0.0740 - val_acc: 0.9952\n",
      "Epoch 16/100\n",
      "593/593 [==============================] - 260s 439ms/step - loss: 0.0517 - acc: 0.9933 - val_loss: 0.0756 - val_acc: 0.9952\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, mask_zero=True, weights=[embedding_matrix], embeddings_regularizer=l2(1e-5))(model_input)\n",
    "x = keras.layers.GRU(64, return_sequences=True, activation=\"relu\", kernel_regularizer=l2(1e-5))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.2)(x)\n",
    "x = keras.layers.GRU(32, return_sequences=False, activation=\"relu\", kernel_regularizer=l2(1e-5))(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('81.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.96425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 464s 783ms/step - loss: 9.3014 - acc: 0.8833 - val_loss: 6.4321 - val_acc: 0.9939\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 458s 773ms/step - loss: 4.6854 - acc: 0.9879 - val_loss: 3.2895 - val_acc: 0.9940\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 458s 773ms/step - loss: 2.4076 - acc: 0.9916 - val_loss: 1.7009 - val_acc: 0.9945\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 459s 775ms/step - loss: 1.2512 - acc: 0.9920 - val_loss: 0.8941 - val_acc: 0.9942\n",
      "Epoch 5/100\n",
      "593/593 [==============================] - 457s 771ms/step - loss: 0.6635 - acc: 0.9915 - val_loss: 0.4857 - val_acc: 0.9942\n",
      "Epoch 6/100\n",
      "593/593 [==============================] - 447s 754ms/step - loss: 0.3663 - acc: 0.9922 - val_loss: 0.2800 - val_acc: 0.9945\n",
      "Epoch 7/100\n",
      "593/593 [==============================] - 393s 663ms/step - loss: 0.2165 - acc: 0.9924 - val_loss: 0.1770 - val_acc: 0.9941\n",
      "Epoch 8/100\n",
      "593/593 [==============================] - 418s 704ms/step - loss: 0.1406 - acc: 0.9924 - val_loss: 0.1250 - val_acc: 0.9949\n",
      "Epoch 9/100\n",
      "593/593 [==============================] - 417s 704ms/step - loss: 0.1008 - acc: 0.9924 - val_loss: 0.0985 - val_acc: 0.9934\n",
      "Epoch 10/100\n",
      "593/593 [==============================] - 417s 703ms/step - loss: 0.0793 - acc: 0.9918 - val_loss: 0.0842 - val_acc: 0.9934\n",
      "Epoch 11/100\n",
      "593/593 [==============================] - 419s 706ms/step - loss: 0.0665 - acc: 0.9922 - val_loss: 0.0766 - val_acc: 0.9936\n",
      "Epoch 12/100\n",
      "593/593 [==============================] - 416s 702ms/step - loss: 0.0580 - acc: 0.9917 - val_loss: 0.0723 - val_acc: 0.9924\n",
      "Epoch 13/100\n",
      "593/593 [==============================] - 380s 641ms/step - loss: 0.0527 - acc: 0.9914 - val_loss: 0.0694 - val_acc: 0.9930\n",
      "Epoch 14/100\n",
      "593/593 [==============================] - 381s 642ms/step - loss: 0.0482 - acc: 0.9903 - val_loss: 0.0700 - val_acc: 0.9914\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix], mask_zero=True, embeddings_regularizer=l2(1e-5))(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.2)(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('82.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "593/593 [==============================] - 391s 660ms/step - loss: 0.0955 - acc: 0.9203 - val_loss: 0.0528 - val_acc: 0.9761\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 382s 644ms/step - loss: 0.0496 - acc: 0.9836 - val_loss: 0.0487 - val_acc: 0.9929\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 380s 640ms/step - loss: 0.0446 - acc: 0.9880 - val_loss: 0.0490 - val_acc: 0.9942\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.1)(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('83.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4738/4738 [==============================] - 1650s 348ms/step - loss: 0.0591 - acc: 0.9534 - val_loss: 0.0470 - val_acc: 0.9934\n",
      "Epoch 2/100\n",
      "4738/4738 [==============================] - 1580s 333ms/step - loss: 0.0426 - acc: 0.9864 - val_loss: 0.0443 - val_acc: 0.9926\n",
      "Epoch 3/100\n",
      "4738/4738 [==============================] - 1529s 323ms/step - loss: 0.0378 - acc: 0.9790 - val_loss: 0.0455 - val_acc: 0.9902\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.1)(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('84.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "593/593 [==============================] - 360s 606ms/step - loss: 0.0779 - accuracy: 0.8124 - val_loss: 0.0485 - val_accuracy: 0.9952\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 351s 591ms/step - loss: 0.0446 - accuracy: 0.9594 - val_loss: 0.0468 - val_accuracy: 0.9946\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 300s 506ms/step - loss: 0.0387 - accuracy: 0.9616 - val_loss: 0.0468 - val_accuracy: 0.9921\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN,))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(50, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "x = keras.layers.Dense(6, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=model_input, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('85.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "593/593 [==============================] - 836s 1s/step - loss: 0.0747 - accuracy: 0.8119 - val_loss: 0.0496 - val_accuracy: 0.9950\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 792s 1s/step - loss: 0.0449 - accuracy: 0.9212 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 785s 1s/step - loss: 0.0392 - accuracy: 0.9257 - val_loss: 0.0454 - val_accuracy: 0.9920\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 744s 1s/step - loss: 0.0345 - accuracy: 0.9067 - val_loss: 0.0470 - val_accuracy: 0.9863\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN,))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(50, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "x = keras.layers.Dense(6, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=model_input, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('86.submission.csv', index=False)\n",
    "# ~ 0.97773"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection / blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.submission.csv        153.submission.csv\n",
      "102.submission.csv        154.submission.csv\n",
      "103.submission.csv        155.submission.csv\n",
      "104.submission.csv        15.ensemble.ipynb\n",
      "105.submission.csv        1.EDA_BASELINES.ipynb\n",
      "106.submission.csv        2.RNN_BASELINES.ipynb\n",
      "10.DoubleEmbedding.ipynb  3.EDA.ipynb\n",
      "111.submission.csv        4.TEXT_PROCESS.ipynb\n",
      "112.submission.csv        5.SentimentFeature_EDA.ipynb\n",
      "113.submission.csv        6.replace_space.ipynb\n",
      "114.submission.csv        71.submission.csv\n",
      "115.submission.csv        72.submission.csv\n",
      "116.submission.csv        73.submission.csv\n",
      "11.Preprocess.ipynb       74.submission.csv\n",
      "121.submission.csv        75.submission.csv\n",
      "122.submission.csv        76.submission.csv\n",
      "123.submission.csv        7.glove.ipynb\n",
      "124.submission.csv        81.submission.csv\n",
      "125.submission.csv        82.submission.csv\n",
      "126.submission.csv        83.submission.csv\n",
      "12.LowerEmbedding.ipynb   84.submission.csv\n",
      "131.submission.csv        85.submission.csv\n",
      "132.submission.csv        86.submission.csv\n",
      "133.submission.csv        8.glove300d.ipynb\n",
      "134.submission.csv        91.submission.csv\n",
      "135.submission.csv        92.submission.csv\n",
      "136.submission.csv        93.submission.csv\n",
      "13.SpellingFix.ipynb      94.submission.csv\n",
      "141.submission.csv        95.submission.csv\n",
      "142.submission.csv        96.submission.csv\n",
      "14.Bertpredict.ipynb      9.GoogleNewsSG300d.ipynb\n",
      "14.BertTrain.ipynb        bert_model.h5\n",
      "150.1.submission.csv      \u001b[0m\u001b[01;34mjigsaw-toxic-comment-classification-challenge\u001b[0m/\n",
      "150.2.submission.csv      processes.ipynb\n",
      "150.3.submission.csv      \u001b[01;34m__pycache__\u001b[0m/\n",
      "150.submission.csv        _todos.md\n",
      "151.submission.csv        tokenization.py\n",
      "152.submission.csv        Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
