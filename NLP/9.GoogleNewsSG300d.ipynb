{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'jigsaw-toxic-comment-classification-challenge'\n",
    "train = pd.read_csv(f'{base_path}/train.csv')\n",
    "test = pd.read_csv(f'{base_path}/test.csv')\n",
    "submission = pd.read_csv(f'{base_path}/sample_submission.csv')\n",
    "test_labels = pd.read_csv(f'{base_path}/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.003527845, 0.13315111)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_FILE = f'{base_path}/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "embeddings_index = {w:wv.get_vector(w) for w in wv.index2word}\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean = all_embs.mean()\n",
    "emb_std = all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing (extract useful information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 30000\n",
    "MAX_SENTENSE_LEN = 100\n",
    "EMBEDDING_SIZE = all_embs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[\"comment_text\"].values\n",
    "y_train = train[LABELS].values\n",
    "x_test = test[\"comment_text\"].values\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=MAX_TOKENS)\n",
    "tokenizer.fit_on_texts(list(x_train) + list(x_test)) # is it a proper trick?\n",
    "\n",
    "x_train, x_test = map(tokenizer.texts_to_sequences, [x_train, x_test])\n",
    "x_train, x_test = map(lambda x: sequence.pad_sequences(x, maxlen=MAX_SENTENSE_LEN), [x_train, x_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_TOKENS, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, EMBEDDING_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_TOKENS: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding & visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-noise (no drop data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 260s 438ms/step - loss: 1.6018 - acc: 0.6797 - val_loss: 0.7545 - val_acc: 0.9952\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 261s 439ms/step - loss: 0.4564 - acc: 0.9587 - val_loss: 0.2636 - val_acc: 0.9952\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 258s 435ms/step - loss: 0.1807 - acc: 0.9764 - val_loss: 0.1281 - val_acc: 0.9952\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 257s 433ms/step - loss: 0.1012 - acc: 0.9808 - val_loss: 0.0884 - val_acc: 0.9952\n",
      "Epoch 5/100\n",
      "593/593 [==============================] - 256s 432ms/step - loss: 0.0753 - acc: 0.9846 - val_loss: 0.0739 - val_acc: 0.9952\n",
      "Epoch 6/100\n",
      "593/593 [==============================] - 257s 433ms/step - loss: 0.0650 - acc: 0.9859 - val_loss: 0.0685 - val_acc: 0.9952\n",
      "Epoch 7/100\n",
      "593/593 [==============================] - 256s 431ms/step - loss: 0.0596 - acc: 0.9883 - val_loss: 0.0664 - val_acc: 0.9952\n",
      "Epoch 8/100\n",
      "593/593 [==============================] - 257s 433ms/step - loss: 0.0563 - acc: 0.9888 - val_loss: 0.0653 - val_acc: 0.9952\n",
      "Epoch 9/100\n",
      "593/593 [==============================] - 257s 433ms/step - loss: 0.0537 - acc: 0.9878 - val_loss: 0.0635 - val_acc: 0.9952\n",
      "Epoch 10/100\n",
      "593/593 [==============================] - 257s 433ms/step - loss: 0.0518 - acc: 0.9906 - val_loss: 0.0629 - val_acc: 0.9952\n",
      "Epoch 11/100\n",
      "593/593 [==============================] - 258s 435ms/step - loss: 0.0503 - acc: 0.9900 - val_loss: 0.0662 - val_acc: 0.9952\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, mask_zero=True, weights=[embedding_matrix], embeddings_regularizer=l2(1e-5))(model_input)\n",
    "x = keras.layers.GRU(64, return_sequences=True, activation=\"relu\", kernel_regularizer=l2(1e-5))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.2)(x)\n",
    "x = keras.layers.GRU(32, return_sequences=False, activation=\"relu\", kernel_regularizer=l2(1e-5))(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('91.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.95921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 418s 706ms/step - loss: 1.5571 - acc: 0.9434 - val_loss: 0.7238 - val_acc: 0.9950\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 416s 701ms/step - loss: 0.4281 - acc: 0.9930 - val_loss: 0.2390 - val_acc: 0.9952\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 402s 678ms/step - loss: 0.1609 - acc: 0.9935 - val_loss: 0.1124 - val_acc: 0.9942\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 423s 712ms/step - loss: 0.0876 - acc: 0.9930 - val_loss: 0.0768 - val_acc: 0.9930\n",
      "Epoch 5/100\n",
      "593/593 [==============================] - 421s 709ms/step - loss: 0.0646 - acc: 0.9925 - val_loss: 0.0646 - val_acc: 0.9932\n",
      "Epoch 6/100\n",
      "593/593 [==============================] - 416s 701ms/step - loss: 0.0557 - acc: 0.9924 - val_loss: 0.0612 - val_acc: 0.9941\n",
      "Epoch 7/100\n",
      "593/593 [==============================] - 415s 701ms/step - loss: 0.0511 - acc: 0.9926 - val_loss: 0.0604 - val_acc: 0.9936\n",
      "Epoch 8/100\n",
      "593/593 [==============================] - 415s 701ms/step - loss: 0.0479 - acc: 0.9925 - val_loss: 0.0586 - val_acc: 0.9937\n",
      "Epoch 9/100\n",
      "593/593 [==============================] - 416s 701ms/step - loss: 0.0454 - acc: 0.9927 - val_loss: 0.0604 - val_acc: 0.9934\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, mask_zero=True, weights=[embedding_matrix], embeddings_regularizer=l2(1e-5))(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.2)(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('92.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.96804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "593/593 [==============================] - 453s 765ms/step - loss: 0.1224 - acc: 0.9089 - val_loss: 0.0530 - val_acc: 0.9895\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 448s 755ms/step - loss: 0.0485 - acc: 0.9918 - val_loss: 0.0493 - val_acc: 0.9861\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 447s 755ms/step - loss: 0.0442 - acc: 0.9894 - val_loss: 0.0480 - val_acc: 0.9841\n",
      "Epoch 4/100\n",
      "593/593 [==============================] - 448s 755ms/step - loss: 0.0412 - acc: 0.9831 - val_loss: 0.0475 - val_acc: 0.9714\n",
      "Epoch 5/100\n",
      "593/593 [==============================] - 447s 754ms/step - loss: 0.0383 - acc: 0.9714 - val_loss: 0.0478 - val_acc: 0.9816\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.1)(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('93.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4738/4738 [==============================] - 1693s 357ms/step - loss: 0.0624 - acc: 0.9664 - val_loss: 0.0491 - val_acc: 0.9931\n",
      "Epoch 2/100\n",
      "4738/4738 [==============================] - 1653s 349ms/step - loss: 0.0424 - acc: 0.9897 - val_loss: 0.0444 - val_acc: 0.9950\n",
      "Epoch 3/100\n",
      "4738/4738 [==============================] - 1642s 347ms/step - loss: 0.0376 - acc: 0.9831 - val_loss: 0.0443 - val_acc: 0.9934\n",
      "Epoch 4/100\n",
      "4738/4738 [==============================] - 1652s 349ms/step - loss: 0.0335 - acc: 0.9359 - val_loss: 0.0463 - val_acc: 0.9919\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN, ))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.SpatialDropout1D(0.1)(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True, activation=\"relu\", recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "model_output = keras.layers.Dense(len(LABELS), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=model_input, outputs=model_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('94.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "593/593 [==============================] - 314s 529ms/step - loss: 0.0835 - accuracy: 0.8609 - val_loss: 0.0488 - val_accuracy: 0.9952\n",
      "Epoch 2/100\n",
      "593/593 [==============================] - 338s 569ms/step - loss: 0.0450 - accuracy: 0.9453 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "Epoch 3/100\n",
      "593/593 [==============================] - 336s 567ms/step - loss: 0.0388 - accuracy: 0.9489 - val_loss: 0.0459 - val_accuracy: 0.9900\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN,))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(50, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "x = keras.layers.Dense(6, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=model_input, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 batch_size=256,\n",
    "                 shuffle=True,\n",
    "                 epochs=100, \n",
    "                 validation_split=0.05,\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=1, \n",
    "                                                          verbose=1)], \n",
    "                 verbose=1)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('95.submission.csv', index=False)\n",
    "\n",
    "# ~ 0.97625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4488/4488 [==============================] - 1267s 282ms/step - loss: 0.0550 - accuracy: 0.9542 - val_loss: 0.0448 - val_accuracy: 0.9939\n",
      "Epoch 2/2\n",
      "4488/4488 [==============================] - 1247s 278ms/step - loss: 0.0386 - accuracy: 0.9681 - val_loss: 0.0447 - val_accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(MAX_SENTENSE_LEN,))\n",
    "x = keras.layers.Embedding(MAX_TOKENS, EMBEDDING_SIZE, weights=[embedding_matrix])(model_input)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = keras.layers.GlobalMaxPool1D()(x)\n",
    "x = keras.layers.Dense(50, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "x = keras.layers.Dense(6, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=model_input, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_split=0.1);\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "submission[LABELS] = y_pred\n",
    "submission.to_csv('96.submission.csv', index=False)\n",
    "# ~ 0.98040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection / blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
