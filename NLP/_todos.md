TODOS:

- 

- Found worthy to explore:
    *o linear model can do well already
    *o ponctuation handeling (fuck!!!)
    * joint words split (fuckyourdaddy)
    * bad word rule coverage & rest/worng cases check (it is fucking good!)
    *o char level n-gram feature 
    *? sentiment helps
    * worng classified check
    *x skip char model (f**k you)
    
    * how to eval embedded quality???????

    * char level embedding 
    * treate this as ture a multilabel problem (binary encode)
    * replace mis-classified training data from testing data.
    
    * external knowledge levergement (bad word dict / corpus)
    * spell check
    * TTA
    * 
    
- Factorization to:
    * fill in missing values
    * detect noises
    
- KEY POINTS:
    * slightly imbalanced data
    
- EDA
    * advanced/ detailed EDA
- validation strategy + model tunning
    * cross-validation
    * adversarial validation
- preprocess
    * de-noise
        * label smoothing
    * NLP
        * stem/ 
- augmentation
    * Lexical Substitution
    * https://zhuanlan.zhihu.com/p/64065441
- model structure 
    * RNN: return_seq&pooling/dual pooling
    * bidirection
    * advanced model: bert?
- optimization
    * topk-loss(OHEM)
- pretrained embedding: 
    * glove
    * w2v
    * fasttext
    
  NOTE: metrix factorization
        factorization machine
  
- ensemble
    * snapshot_ensemble
    * ensemble


