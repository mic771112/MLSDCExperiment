{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jigsaw-toxic-comment-classification-challenge/train.csv')\n",
    "test = pd.read_csv('jigsaw-toxic-comment-classification-challenge/test.csv')\n",
    "test_labels = pd.read_csv('jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n",
    "sample_submission = pd.read_csv('jigsaw-toxic-comment-classification-challenge/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing (extract useful information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment features\n",
    "\n",
    "from textblob import TextBlob\n",
    "from multiprocess import Pool\n",
    "\n",
    "SENTIMENT = ['polarity', 'subjectivity']\n",
    "with Pool() as pool:\n",
    "    train['polarity'] = pool.map(lambda text: TextBlob(text).polarity, train[COMMENT])\n",
    "    train['subjectivity'] = pool.map(lambda text: TextBlob(text).subjectivity, train[COMMENT])\n",
    "    test['polarity'] = pool.map(lambda text: TextBlob(text).polarity, test[COMMENT])\n",
    "    test['subjectivity'] = pool.map(lambda text: TextBlob(text).subjectivity, test[COMMENT])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "import unicodedata\n",
    "import warnings\n",
    "from string import ascii_letters, digits, punctuation\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "\n",
    "class BaseFilter:\n",
    "    \"\"\"Base filter class, it does NOTHING.\n",
    "    This class is design for providing ``__repr__`` string, which is useful in\n",
    "    python interactive prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<%s>' % type(self).__name__\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "        return text\n",
    "\n",
    "\n",
    "class GeneralFilter(BaseFilter):\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{clsn} repl=`{repl}`>'.format(clsn=type(self).__name__,\n",
    "                                               repl=self.repl)\n",
    "\n",
    "    def __call__(self, s: str, count: int = 0):\n",
    "        return self.pattern.sub(self.repl, s, count)\n",
    "\n",
    "\n",
    "class EmailFilter(GeneralFilter):\n",
    "    \n",
    "    def __init__(self, replace=' '):\n",
    "        if isinstance(replace, str):\n",
    "            self.repl = replace\n",
    "        else:\n",
    "            self.repl = lambda match: next(replace) # for iterator tag\n",
    "        self.expression = r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+'\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "\n",
    "class URLFilter(GeneralFilter):\n",
    "    \n",
    "    # copied from string_constants.py\n",
    "    schemes = list(map(lambda x: '{}:\\/\\/'.format(x), (\"http\", \"https\", \"ftp\", \"sftp\", \"irc\", \"magnet\", \"file\", \"data\"))) + ['www.']\n",
    "    schemes_lenient = list(map(lambda x: '{}:\\/\\/'.format(x), (\"h?ttp\", \"h?ttps\", \"ftp\", \"sftp\", \"irc\", \"magnet\", \"file\", \"data\"))) + ['www.']\n",
    "\n",
    "    # from RFC\n",
    "    gen_delims = \":/?#[]@\"\n",
    "    sub_delims = \"!$&'()*+;=%\"\n",
    "    reserved = gen_delims + sub_delims\n",
    "    unreserved = ascii_letters + digits + \"-._~\"\n",
    "    valid_uri_characters = reserved + unreserved\n",
    "\n",
    "    def __init__(self, replace=' ', allow_common_typoes=True):\n",
    "        \n",
    "        if isinstance(replace, str):\n",
    "            self.repl = replace\n",
    "        else:\n",
    "            self.repl = lambda match: next(replace) # for iterator tag\n",
    "\n",
    "        if allow_common_typoes:\n",
    "            self.expression = r\"((?:{})[{}]+)\".format(\"|\".join(self.schemes), re.escape(self.valid_uri_characters))\n",
    "        else:\n",
    "            self.expression = r\"((?:{})[{}]+)\".format(\"|\".join(self.schemes_lenient), re.escape(self.valid_uri_characters))\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "\n",
    "class EscapeCharFilter(GeneralFilter):\n",
    "\n",
    "    def __init__(self, replace:str=' '):\n",
    "        self.repl = replace\n",
    "        self.expression = r'([{}])'.format('\\r\\n\\t\\v')\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "\n",
    "class InvisableCharFilter(GeneralFilter):\n",
    "    \n",
    "    def __init__(self, replace:str='', ):\n",
    "        self.repl = replace\n",
    "        self.expression = r'([{}])'.format(r'\\xa0\\xad\\u200c')\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "\n",
    "class KeyWordsFilter(GeneralFilter):\n",
    "    \n",
    "    def __init__(self, replace:str=' ', keywords=('mailto',)):\n",
    "        self.repl = replace\n",
    "        self.expression = r'({})'.format('|'.join(map(lambda x: '({})'.format(x), keywords)))\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "\n",
    "class MultiSpacesFilter(GeneralFilter):\n",
    "    \n",
    "    def __init__(self, replace:str=' '):\n",
    "        self.repl = replace\n",
    "        self.expression = r'(\\s+)'\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "\n",
    "class FilterNonChars(GeneralFilter):\n",
    "\n",
    "    def __init__(self, replace:str=' '):\n",
    "        self.repl = replace\n",
    "        self.expression = r'(\\W+)'\n",
    "        self.pattern = re.compile(self.expression)\n",
    "        \n",
    "        \n",
    "class HTMLFilter(GeneralFilter):\n",
    "    def __init__(self, replace:str=''):\n",
    "        self.repl = replace\n",
    "        self.expression = \"<[^>]*>\"\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "class HTML2Text:\n",
    "    \n",
    "    def __init__(self, filters=('script', 'style', 'meta', 'noscript')):\n",
    "        self.filters = filters\n",
    "\n",
    "    def extract_text_from_html(self, html:str):\n",
    "\n",
    "        soup = BeautifulSoup(html, features='lxml')\n",
    "        for script in soup(self.filters): # remove all javascript and stylesheet code\n",
    "            script.decompose()\n",
    "        return soup.get_text()\n",
    "    \n",
    "    def __call__(self, html:str):\n",
    "        try:\n",
    "            return self.extract_text_from_html(html)\n",
    "        except:\n",
    "            return str()\n",
    "\n",
    "\n",
    "\n",
    "class UnicodeStandarizer:\n",
    "    \n",
    "    def __init__(self, method='NFKC'): # NFD, NFC, NFKD, NFKC\n",
    "        self.method = method\n",
    "    \n",
    "    def __call__(self, text:str):\n",
    "        return unicodedata.normalize(self.method, text)\n",
    "\n",
    "\n",
    "class Stripper:\n",
    "    @staticmethod    \n",
    "    def __call__(text:str):\n",
    "        return text.strip()\n",
    "\n",
    "\n",
    "class Lowercasting:\n",
    "    @staticmethod    \n",
    "    def __call__(text:str):\n",
    "        return text.lower()\n",
    "\n",
    "\n",
    "class SequentialProcessor(BaseFilter):\n",
    "    \"\"\"Sequential processor: A class provide an interface to create integral\n",
    "    processor that would sequentially filter text by the given filters.\n",
    "    Usage::\n",
    "        text_preprocessor = SequentialProcessor(\n",
    "            UnicodeStandarizer(),\n",
    "            HTML2Text(),\n",
    "            InvisableCharFilter(),\n",
    "            LIDFilter(),\n",
    "            Lowercasting(),\n",
    "            KeyWordsFilter(),\n",
    "            MultiSpacesFilter(),\n",
    "            Stripper(),\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *processors):\n",
    "        self.pipeline = processors\n",
    "\n",
    "    def __repr__(self):\n",
    "        if len(self.pipeline) == 1:\n",
    "            children_desc = repr(self.pipeline)\n",
    "        else:\n",
    "            # use textwrap to support nested processors\n",
    "            children_desc = '\\n' + ',\\n'.join(\n",
    "                textwrap.indent(repr(p), ' ' * 4)\n",
    "                for p in self.pipeline)\n",
    "        return '<{clsn} [{child}]>'.format(clsn=type(self).__name__,\n",
    "                                           child=children_desc)\n",
    "\n",
    "    def __call__(self, text: str):\n",
    "        for processor in self.pipeline:\n",
    "            text = processor(text)\n",
    "        return text\n",
    "\n",
    "class GeneralProcessor(SequentialProcessor):\n",
    "    pass\n",
    "\n",
    "class KeepWordSpace(GeneralFilter):\n",
    "    def __init__(self, replace:str=' '):\n",
    "        self.repl = replace\n",
    "        self.expression = r'([^\\w\\s])'\n",
    "        self.pattern = re.compile(self.expression)\n",
    "        \n",
    "class WordModelPreprocessor(GeneralProcessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = (UnicodeStandarizer(), HTML2Text(), URLFilter(), EscapeCharFilter(), KeepWordSpace(), Lowercasting(), MultiSpacesFilter(), Stripper())\n",
    "\n",
    "class LIDFilter(GeneralFilter):\n",
    "    \n",
    "    def __init__(self, replace=' '):\n",
    "        self.repl = replace\n",
    "        filters = EmailFilter(), URLFilter(), EscapeCharFilter(), FilterNonChars()\n",
    "        self.expression = '|'.join(list(map(lambda x: x.expression, filters)))\n",
    "        self.pattern = re.compile(self.expression)\n",
    "\n",
    "class TextPreprocessor(GeneralProcessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = (UnicodeStandarizer(), HTML2Text(), InvisableCharFilter(), LIDFilter(), Lowercasting(), KeyWordsFilter(), MultiSpacesFilter(), Stripper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceRemove:\n",
    "    @staticmethod    \n",
    "    def __call__(text:str):\n",
    "        return text.replace(' ', '').replace('\\t', '').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(GeneralProcessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = (UnicodeStandarizer(), HTML2Text(), URLFilter(), EmailFilter(), InvisableCharFilter(), LIDFilter(), Lowercasting(), KeyWordsFilter(), MultiSpacesFilter(), Stripper(), SpaceRemove())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor()\n",
    "with Pool() as pool:\n",
    "    train[COMMENT] = pool.map(text_preprocessor, train[COMMENT])\n",
    "    test[COMMENT] = pool.map(text_preprocessor, test[COMMENT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding & visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-noise (no drop data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(max_features=16384)\n",
    "\n",
    "x_train = vec.fit_transform(train[COMMENT])\n",
    "x_test = vec.transform(test[COMMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sentiment = sparse.hstack([x_train, train['polarity'].values.reshape(-1, 1), train['subjectivity'].values.reshape(-1, 1)])\n",
    "x_test_sentiment = sparse.hstack([x_test, test['polarity'].values.reshape(-1, 1), test['subjectivity'].values.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 16386)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "\n",
    "x_train_char = vec.fit_transform(train[COMMENT])\n",
    "x_test_char = vec.transform(test[COMMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_char_sentiment = sparse.hstack([x_train_char, train['polarity'].values.reshape(-1, 1), train['subjectivity'].values.reshape(-1, 1)])\n",
    "x_test_char_sentiment = sparse.hstack([x_test_char, test['polarity'].values.reshape(-1, 1), test['subjectivity'].values.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 421505)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_char_sentiment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 64.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "# baseline model with preprocess & sentiment appended.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {l: LogisticRegression(n_jobs=-1) for l in LABELS}\n",
    "[models[l].fit(x_train_sentiment, train[l]) for l in LABELS]\n",
    "for l in LABELS:\n",
    "    sample_submission[l] = models[l].predict_proba(x_test_sentiment)[:, 1]\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# ~ 72.58% (as no more tokens there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 64.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "# baseline model with preprocess, 2-4 char grams & sentiment appended.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {l: LogisticRegression(n_jobs=-1) for l in LABELS}\n",
    "[models[l].fit(x_train_char_sentiment, train[l]) for l in LABELS]\n",
    "for l in LABELS:\n",
    "    sample_submission[l] = models[l].predict_proba(x_test_char_sentiment)[:, 1]\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# ~ 97.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 64.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "# baseline model with preprocess, 2-4 char grams & sentiment appended, weaker regularization.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {l: LogisticRegression(C=3, n_jobs=-1) for l in LABELS}\n",
    "[models[l].fit(x_train_char_sentiment, train[l]) for l in LABELS]\n",
    "for l in LABELS:\n",
    "    sample_submission[l] = models[l].predict_proba(x_test_char_sentiment)[:, 1]\n",
    "sample_submission.to_csv('3.submission.csv', index= False)\n",
    "\n",
    "# ~ 97.47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# baseline model with preprocess, 2-4 char grams & sentiment appended, weaker regularization.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {l: LogisticRegression(C=3, n_jobs=-1, solver='saga') for l in LABELS}\n",
    "[models[l].fit(x_train_char_sentiment, train[l]) for l in LABELS]\n",
    "for l in LABELS:\n",
    "    sample_submission[l] = models[l].predict_proba(x_test_char_sentiment)[:, 1]\n",
    "sample_submission.to_csv('4.submission.csv', index=False)\n",
    "\n",
    "# ~ 97.46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 64.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "# baseline model with preprocess, 2-4 char grams & sentiment appended, weaker regularization.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {l: LogisticRegression(C=100, n_jobs=-1) for l in LABELS}\n",
    "[models[l].fit(x_train_char_sentiment, train[l]) for l in LABELS]\n",
    "for l in LABELS:\n",
    "    sample_submission[l] = models[l].predict_proba(x_test_char_sentiment)[:, 1]\n",
    "sample_submission.to_csv('5.submission.csv', index=False)\n",
    "\n",
    "# ~ 96.68%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection / blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
