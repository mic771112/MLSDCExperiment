{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "COMMENT = 'comment_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jigsaw-toxic-comment-classification-challenge/train.csv')\n",
    "test = pd.read_csv('jigsaw-toxic-comment-classification-challenge/test.csv')\n",
    "submission = pd.read_csv('jigsaw-toxic-comment-classification-challenge/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', s).split()\n",
    "vec = TfidfVectorizer(max_features=16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vec.fit_transform(train[COMMENT])\n",
    "x_test = vec.transform(test[COMMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "models = {l: LogisticRegression() for l in LABELS}\n",
    "[models[l].fit(x_train, train[l]) for l in LABELS]\n",
    "for l in LABELS:\n",
    "    submission[l] = models[l].predict_proba(x_test)[:, 1]\n",
    "submission.to_csv('1.submission.csv', index=False)\n",
    "\n",
    "# ~ 97.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shanger_lin/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for l in LABELS:\n",
    "    submission[l] = models[l].predict_proba(x_test)[:, 1]\n",
    "submission.loc[:, 'severe_toxic'][submission['toxic'] < 0.2] = 0\n",
    "submission.to_csv('2.submission.csv', index=False)\n",
    "# ~ 97.46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_input = keras.Input(shape=[x_test.shape[1]])\n",
    "l = layers.Dense(1024, activation='relu', kernel_regularizer=l2(1e-5))(keras_input)\n",
    "l = layers.Dense(512, activation='relu', kernel_regularizer=l2(1e-5))(l)\n",
    "l = layers.Dense(128, activation='relu', kernel_regularizer=l2(1e-5))(l)\n",
    "keras_output = layers.Dense(6, activation='sigmoid')(l)\n",
    "model = keras.Model(keras_input, keras_output)\n",
    "model.compile(keras.optimizers.Adam(3e-4), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1185/1185 [==============================] - 163s 137ms/step - loss: 0.0851 - acc: 0.9720 - val_loss: 0.0624 - val_acc: 0.9952\n",
      "Epoch 2/10\n",
      "1185/1185 [==============================] - 162s 136ms/step - loss: 0.0534 - acc: 0.9890 - val_loss: 0.0596 - val_acc: 0.9927\n",
      "Epoch 3/10\n",
      "1185/1185 [==============================] - 159s 134ms/step - loss: 0.0469 - acc: 0.9842 - val_loss: 0.0607 - val_acc: 0.9951\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f61cc5306a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.todense(), \n",
    "          train[LABELS], \n",
    "          validation_split=0.05,\n",
    "          epochs=10, \n",
    "          batch_size=128,\n",
    "          shuffle=True, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, verbose=1), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in enumerate(LABELS):\n",
    "    submission[l] = y_pred[:, i]\n",
    "submission.to_csv('3.submission.csv', index=False)\n",
    "# ~ 97.37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "models = {l: RandomForestRegressor(n_estimators=1, n_jobs=-1, max_depth=100) for l in LABELS}\n",
    "\n",
    "for l in LABELS:\n",
    "    print(l)\n",
    "    models[l].fit(x_train, train[l])\n",
    "    submission[l] = models[l].predict(x_test)\n",
    "submission.to_csv('4.submission.csv', index=False)\n",
    "\n",
    "# ~ 58.21% (might dure to max_depth and n_estimators limit for training time constrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {l: LogisticRegression(class_weight='balanced') for l in LABELS}\n",
    "for l in LABELS:\n",
    "    models[l].fit(x_train, train[l])\n",
    "    submission[l] = models[l].predict_proba(x_test)[:, 1]\n",
    "submission.to_csv('5.submission.csv', index=False)\n",
    "\n",
    "# ~ 97.49%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.ensemble.ExtraTreesClassifier(n_jobs=-1, n_estimators=10)\n",
    "model.fit(x_train, train[LABELS])\n",
    "y_pred = model.predict_proba(x_test)[0][:, 1]\n",
    "for i, l in enumerate(LABELS):\n",
    "    submission[l] = y_pred\n",
    "submission.to_csv('6.submission.csv', index=False)\n",
    "# ~ 94.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.ensemble.ExtraTreesClassifier(n_jobs=-1, n_estimators=1000)\n",
    "model.fit(x_train, train[LABELS])\n",
    "y_pred = model.predict_proba(x_test)[0][:, 1]\n",
    "for i, l in enumerate(LABELS):\n",
    "    submission[l] = y_pred\n",
    "submission.to_csv('7.submission.csv', index=False)\n",
    "# ~ 95.66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
