{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow\n",
    "# !pip uninstall tensorflow-gpu\n",
    "# !pip uninstall tf-nightly\n",
    "\n",
    "# !pip install  tensorflow\n",
    "# !pip install tensorflow-gpu\n",
    "# !pip install  tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
    "# !unzip -q kagglecatsanddogs_3367a.zip\n",
    "# !ls PetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23410 files belonging to 2 classes.\n",
      "Using 18728 files for training.\n",
      "Found 23410 files belonging to 2 classes.\n",
      "Using 4682 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (16, 16)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes, dual=False):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        if dual:\n",
    "            x = layers.concatenate([layers.MaxPooling2D(3, strides=2, padding=\"same\")(x),\n",
    "                                    layers.AveragePooling2D(3, strides=2, padding=\"same\")(x)])\n",
    "            residual = layers.Conv2D(size*2, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        else:\n",
    "            x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "            residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "                previous_block_activation\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Project residual\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2, dual=True)\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from tensorflow.python.framework import smart_cond\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from tensorflow.python.keras.utils import losses_utils\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops.losses import util as tf_losses_util\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "class LossFunctionWrapper(Loss):\n",
    "    def __init__(self,\n",
    "        fn,\n",
    "        reduction=losses_utils.ReductionV2.AUTO,\n",
    "        name=None,\n",
    "        **kwargs):\n",
    "        super(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)\n",
    "        self.fn = fn\n",
    "        self._fn_kwargs = kwargs\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        if tensor_util.is_tensor(y_pred) and tensor_util.is_tensor(y_true):\n",
    "            y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n",
    "                y_pred, y_true)\n",
    "        return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = dict()\n",
    "        for k, v in six.iteritems(self._fn_kwargs):\n",
    "            config[k] = K.eval(v) if tf_utils.is_tensor_or_variable(v) else v\n",
    "        base_config = super(LossFunctionWrapper, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "@keras_export('keras.metrics.top_K_binary_crossentropy',\n",
    "              'keras.losses.top_K_binary_crossentropy')\n",
    "def top_k_binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0, k=0):  # pylint: disable=missing-docstring\n",
    "    assert k >= 0\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "    label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
    "    \n",
    "    def _smooth_labels():\n",
    "        return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
    "    \n",
    "    y_true = smart_cond.smart_cond(label_smoothing,\n",
    "                                   _smooth_labels, lambda: y_true)\n",
    "    \n",
    "    losses = K.binary_crossentropy(y_true, y_pred, from_logits=from_logits)\n",
    "    \n",
    "    if k==0:\n",
    "        top_k_losses = losses\n",
    "    else:\n",
    "        k_to_get = K.min([k, tf.shape(losses)[0]]) # k = min(batch, k)\n",
    "        top_k_losses = tf.nn.top_k(tf.reshape(losses, (1, -1)), k_to_get).values\n",
    "        top_k_losses = tf.reshape(top_k_losses, (-1, 1))\n",
    "        \n",
    "    return K.mean(top_k_losses, axis=-1)\n",
    "\n",
    "@keras_export('keras.losses.TopKBinaryCrossentropy')\n",
    "class TopKBinaryCrossentropy(LossFunctionWrapper):\n",
    "    def __init__(self,\n",
    "        from_logits=False,\n",
    "        label_smoothing=0,\n",
    "        reduction=losses_utils.ReductionV2.AUTO,\n",
    "        name='top_K_binary_crossentropy',\n",
    "        k=0\n",
    "                ):\n",
    "        super(TopKBinaryCrossentropy, self).__init__(\n",
    "            top_k_binary_crossentropy,\n",
    "            name=name,\n",
    "            reduction=reduction,\n",
    "            from_logits=from_logits,\n",
    "            label_smoothing=label_smoothing,\n",
    "            k=k)\n",
    "        self.from_logits = from_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.6834 - accuracy: 0.5952 - val_loss: 0.6778 - val_accuracy: 0.5562\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6197 - accuracy: 0.6602 - val_loss: 0.6787 - val_accuracy: 0.5692\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5993 - accuracy: 0.6889 - val_loss: 0.6214 - val_accuracy: 0.6709\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5807 - accuracy: 0.7004 - val_loss: 0.5868 - val_accuracy: 0.6933\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5715 - accuracy: 0.7096 - val_loss: 0.6066 - val_accuracy: 0.6531\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.5615 - accuracy: 0.7148 - val_loss: 0.6293 - val_accuracy: 0.6726\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5478 - accuracy: 0.7273 - val_loss: 0.5649 - val_accuracy: 0.7050\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.5441 - accuracy: 0.7299 - val_loss: 0.7210 - val_accuracy: 0.6132\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5350 - accuracy: 0.7318 - val_loss: 0.5189 - val_accuracy: 0.7460\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5237 - accuracy: 0.7419 - val_loss: 0.6712 - val_accuracy: 0.6220\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5220 - accuracy: 0.7472 - val_loss: 0.6334 - val_accuracy: 0.6689\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.5166 - accuracy: 0.7456 - val_loss: 0.5577 - val_accuracy: 0.7074\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.5111 - accuracy: 0.7478 - val_loss: 0.5890 - val_accuracy: 0.6988\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5086 - accuracy: 0.7556 - val_loss: 0.6081 - val_accuracy: 0.6613\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4990 - accuracy: 0.7570 - val_loss: 0.5295 - val_accuracy: 0.7407\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5014 - accuracy: 0.7580 - val_loss: 0.5363 - val_accuracy: 0.7217\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.4922 - accuracy: 0.7670 - val_loss: 0.5440 - val_accuracy: 0.7087\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4909 - accuracy: 0.7653 - val_loss: 0.4993 - val_accuracy: 0.7495\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4859 - accuracy: 0.7644 - val_loss: 0.5800 - val_accuracy: 0.6873\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4919 - accuracy: 0.7644 - val_loss: 0.5260 - val_accuracy: 0.7232\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7469\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4764 - accuracy: 0.7735 - val_loss: 0.5277 - val_accuracy: 0.7345\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4700 - accuracy: 0.7774 - val_loss: 0.6028 - val_accuracy: 0.6995\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7527\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4639 - accuracy: 0.7817 - val_loss: 0.6820 - val_accuracy: 0.6587\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4631 - accuracy: 0.7841 - val_loss: 0.5716 - val_accuracy: 0.7025\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4610 - accuracy: 0.7833 - val_loss: 0.4906 - val_accuracy: 0.7612\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7371\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4529 - accuracy: 0.7879 - val_loss: 0.5347 - val_accuracy: 0.7405\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4514 - accuracy: 0.7890 - val_loss: 0.5190 - val_accuracy: 0.7512\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4477 - accuracy: 0.7912 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.6031 - val_accuracy: 0.7097\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.4368 - accuracy: 0.7937 - val_loss: 0.5480 - val_accuracy: 0.7305\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4431 - accuracy: 0.7962 - val_loss: 0.4911 - val_accuracy: 0.7661\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4346 - accuracy: 0.7988 - val_loss: 0.5029 - val_accuracy: 0.7578\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4358 - accuracy: 0.7996 - val_loss: 0.6127 - val_accuracy: 0.7187\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4315 - accuracy: 0.8004 - val_loss: 0.4985 - val_accuracy: 0.7591\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4261 - accuracy: 0.8010 - val_loss: 0.4986 - val_accuracy: 0.7589\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4262 - accuracy: 0.8028 - val_loss: 0.7233 - val_accuracy: 0.6927\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4265 - accuracy: 0.8018 - val_loss: 0.5380 - val_accuracy: 0.7458\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4170 - accuracy: 0.8062 - val_loss: 0.5507 - val_accuracy: 0.7446\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4162 - accuracy: 0.8049 - val_loss: 0.5175 - val_accuracy: 0.7621\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4136 - accuracy: 0.8110 - val_loss: 0.4959 - val_accuracy: 0.7659\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4093 - accuracy: 0.8120 - val_loss: 0.5593 - val_accuracy: 0.7407\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4100 - accuracy: 0.8099 - val_loss: 0.5770 - val_accuracy: 0.7375\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.4031 - accuracy: 0.8118 - val_loss: 0.5824 - val_accuracy: 0.7428\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.4051 - accuracy: 0.8143 - val_loss: 0.5934 - val_accuracy: 0.7409\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.4075 - accuracy: 0.8100 - val_loss: 0.5395 - val_accuracy: 0.7537\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.3992 - accuracy: 0.8207 - val_loss: 0.5364 - val_accuracy: 0.7482\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.3969 - accuracy: 0.8202 - val_loss: 0.6993 - val_accuracy: 0.7012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ee35de550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=TopKBinaryCrossentropy(k=0),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6742 - accuracy: 0.8187 - val_loss: 0.7724 - val_accuracy: 0.7646\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 41s 69ms/step - loss: 0.6659 - accuracy: 0.8195 - val_loss: 0.7938 - val_accuracy: 0.7424\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6643 - accuracy: 0.8218 - val_loss: 0.7497 - val_accuracy: 0.7584\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6618 - accuracy: 0.8238 - val_loss: 0.7601 - val_accuracy: 0.7544\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6665 - accuracy: 0.8162 - val_loss: 0.7328 - val_accuracy: 0.7642\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 40s 69ms/step - loss: 0.6607 - accuracy: 0.8240 - val_loss: 0.7302 - val_accuracy: 0.7678\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6584 - accuracy: 0.8250 - val_loss: 0.7349 - val_accuracy: 0.7730\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6584 - accuracy: 0.8230 - val_loss: 0.7893 - val_accuracy: 0.7473\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6589 - accuracy: 0.8250 - val_loss: 0.7403 - val_accuracy: 0.7640\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6530 - accuracy: 0.8281 - val_loss: 0.7779 - val_accuracy: 0.7559\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.6535 - accuracy: 0.8266 - val_loss: 0.7581 - val_accuracy: 0.7646\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.6541 - accuracy: 0.8272 - val_loss: 0.7631 - val_accuracy: 0.7565\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6514 - accuracy: 0.8295 - val_loss: 0.7493 - val_accuracy: 0.7644\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6503 - accuracy: 0.8296 - val_loss: 0.7723 - val_accuracy: 0.7552\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6501 - accuracy: 0.8280 - val_loss: 0.7969 - val_accuracy: 0.7497\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 44s 74ms/step - loss: 0.6472 - accuracy: 0.8315 - val_loss: 0.8741 - val_accuracy: 0.7157\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 0.6434 - accuracy: 0.8319 - val_loss: 0.8675 - val_accuracy: 0.7352\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 50s 86ms/step - loss: 0.6420 - accuracy: 0.8316 - val_loss: 0.8317 - val_accuracy: 0.7394\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.6421 - accuracy: 0.8351 - val_loss: 0.7807 - val_accuracy: 0.7651\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.6378 - accuracy: 0.8364 - val_loss: 0.8717 - val_accuracy: 0.7300\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.6367 - accuracy: 0.8351 - val_loss: 0.7957 - val_accuracy: 0.7661\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 41s 69ms/step - loss: 0.6341 - accuracy: 0.8400 - val_loss: 0.8490 - val_accuracy: 0.7343\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6301 - accuracy: 0.8401 - val_loss: 0.8656 - val_accuracy: 0.7330\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6306 - accuracy: 0.8399 - val_loss: 0.8406 - val_accuracy: 0.7437\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6313 - accuracy: 0.8393 - val_loss: 0.8195 - val_accuracy: 0.7561\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6254 - accuracy: 0.8446 - val_loss: 0.8781 - val_accuracy: 0.7243\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6281 - accuracy: 0.8428 - val_loss: 0.8794 - val_accuracy: 0.7134\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6232 - accuracy: 0.8435 - val_loss: 0.8542 - val_accuracy: 0.7343\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.6203 - accuracy: 0.8461 - val_loss: 0.7866 - val_accuracy: 0.7612\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.6181 - accuracy: 0.8465 - val_loss: 0.8817 - val_accuracy: 0.7334\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.6188 - accuracy: 0.8463 - val_loss: 0.8267 - val_accuracy: 0.7454\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6116 - accuracy: 0.8499 - val_loss: 0.8516 - val_accuracy: 0.7518\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6120 - accuracy: 0.8514 - val_loss: 0.8240 - val_accuracy: 0.7648\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.6101 - accuracy: 0.8516 - val_loss: 0.9415 - val_accuracy: 0.7221\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6013 - accuracy: 0.8564 - val_loss: 0.9932 - val_accuracy: 0.7057\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6077 - accuracy: 0.8523 - val_loss: 0.8517 - val_accuracy: 0.7446\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.6089 - accuracy: 0.8516 - val_loss: 1.0017 - val_accuracy: 0.6993\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6056 - accuracy: 0.8532 - val_loss: 0.8541 - val_accuracy: 0.7576\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6011 - accuracy: 0.8556 - val_loss: 0.7942 - val_accuracy: 0.7742\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.5953 - accuracy: 0.8569 - val_loss: 1.0744 - val_accuracy: 0.6888\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.5984 - accuracy: 0.8574 - val_loss: 0.8759 - val_accuracy: 0.7448\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.6010 - accuracy: 0.8544 - val_loss: 0.9187 - val_accuracy: 0.7258\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.5847 - accuracy: 0.8617 - val_loss: 0.8502 - val_accuracy: 0.7593\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.5895 - accuracy: 0.8597 - val_loss: 0.8783 - val_accuracy: 0.7546\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5922 - accuracy: 0.8589 - val_loss: 0.8791 - val_accuracy: 0.7561\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.5861 - accuracy: 0.8610 - val_loss: 0.8604 - val_accuracy: 0.7608\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.5799 - accuracy: 0.8652 - val_loss: 0.9320 - val_accuracy: 0.7460\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.5837 - accuracy: 0.8644 - val_loss: 0.9066 - val_accuracy: 0.7428\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.5746 - accuracy: 0.8678 - val_loss: 0.8546 - val_accuracy: 0.7619\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.5776 - accuracy: 0.8635 - val_loss: 0.9807 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ee344c2e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=TopKBinaryCrossentropy(k=16),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3673 - accuracy: 0.8697 - val_loss: 0.8060 - val_accuracy: 0.7106\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.3576 - accuracy: 0.8713 - val_loss: 0.7593 - val_accuracy: 0.7202\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3558 - accuracy: 0.8709 - val_loss: 0.8166 - val_accuracy: 0.7371\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.3533 - accuracy: 0.8727 - val_loss: 0.6704 - val_accuracy: 0.7608\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.3521 - accuracy: 0.8723 - val_loss: 0.8213 - val_accuracy: 0.7230\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3457 - accuracy: 0.8744 - val_loss: 0.7224 - val_accuracy: 0.7589\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3444 - accuracy: 0.8749 - val_loss: 0.7584 - val_accuracy: 0.7379\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3473 - accuracy: 0.8738 - val_loss: 0.7771 - val_accuracy: 0.7373\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.3407 - accuracy: 0.8769 - val_loss: 0.7251 - val_accuracy: 0.7516\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3319 - accuracy: 0.8799 - val_loss: 0.7358 - val_accuracy: 0.7439\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3420 - accuracy: 0.8759 - val_loss: 0.7446 - val_accuracy: 0.7469\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3367 - accuracy: 0.8794 - val_loss: 0.7268 - val_accuracy: 0.7428\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3329 - accuracy: 0.8786 - val_loss: 0.6938 - val_accuracy: 0.7493\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3280 - accuracy: 0.8805 - val_loss: 0.6676 - val_accuracy: 0.7666\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3352 - accuracy: 0.8775 - val_loss: 0.7196 - val_accuracy: 0.7448\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3279 - accuracy: 0.8825 - val_loss: 0.7098 - val_accuracy: 0.7595\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.6762 - val_accuracy: 0.7672\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3179 - accuracy: 0.8854 - val_loss: 0.7256 - val_accuracy: 0.7471\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3246 - accuracy: 0.8854 - val_loss: 0.6835 - val_accuracy: 0.7631\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3171 - accuracy: 0.8847 - val_loss: 0.6970 - val_accuracy: 0.7601\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3149 - accuracy: 0.8873 - val_loss: 0.7706 - val_accuracy: 0.7394\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3112 - accuracy: 0.8860 - val_loss: 0.6813 - val_accuracy: 0.7606\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3110 - accuracy: 0.8885 - val_loss: 0.8406 - val_accuracy: 0.7330\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 43s 73ms/step - loss: 0.3057 - accuracy: 0.8898 - val_loss: 0.8777 - val_accuracy: 0.7127\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3099 - accuracy: 0.8865 - val_loss: 0.7020 - val_accuracy: 0.7540\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3036 - accuracy: 0.8922 - val_loss: 0.8064 - val_accuracy: 0.7381\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.3025 - accuracy: 0.8912 - val_loss: 0.6945 - val_accuracy: 0.7678\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.3010 - accuracy: 0.8926 - val_loss: 0.7790 - val_accuracy: 0.7469\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2986 - accuracy: 0.8930 - val_loss: 0.7583 - val_accuracy: 0.7557\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2964 - accuracy: 0.8948 - val_loss: 0.6773 - val_accuracy: 0.7698\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2970 - accuracy: 0.8921 - val_loss: 0.7895 - val_accuracy: 0.7424\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2944 - accuracy: 0.8982 - val_loss: 0.7453 - val_accuracy: 0.7514\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 41s 70ms/step - loss: 0.3020 - accuracy: 0.8949 - val_loss: 0.7261 - val_accuracy: 0.7495\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2916 - accuracy: 0.8938 - val_loss: 0.8912 - val_accuracy: 0.7170\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2881 - accuracy: 0.8962 - val_loss: 0.9430 - val_accuracy: 0.7140\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2887 - accuracy: 0.8965 - val_loss: 0.9767 - val_accuracy: 0.7087\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2907 - accuracy: 0.8930 - val_loss: 0.7439 - val_accuracy: 0.7567\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2817 - accuracy: 0.9004 - val_loss: 0.7793 - val_accuracy: 0.7446\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2841 - accuracy: 0.8993 - val_loss: 0.6855 - val_accuracy: 0.7572\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2857 - accuracy: 0.8959 - val_loss: 0.8400 - val_accuracy: 0.7367\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2806 - accuracy: 0.8976 - val_loss: 0.7445 - val_accuracy: 0.7717\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2833 - accuracy: 0.9000 - val_loss: 0.7422 - val_accuracy: 0.7640\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2768 - accuracy: 0.9035 - val_loss: 0.7344 - val_accuracy: 0.7655\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.2821 - accuracy: 0.8972 - val_loss: 0.8125 - val_accuracy: 0.7343\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 41s 71ms/step - loss: 0.2795 - accuracy: 0.9006 - val_loss: 0.7023 - val_accuracy: 0.7608\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2726 - accuracy: 0.9046 - val_loss: 0.8222 - val_accuracy: 0.7452\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2698 - accuracy: 0.9055 - val_loss: 0.8825 - val_accuracy: 0.7311\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 42s 71ms/step - loss: 0.2709 - accuracy: 0.9028 - val_loss: 0.9913 - val_accuracy: 0.7093\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2715 - accuracy: 0.9026 - val_loss: 0.7391 - val_accuracy: 0.7719\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 42s 72ms/step - loss: 0.2671 - accuracy: 0.9058 - val_loss: 0.8120 - val_accuracy: 0.7610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ebc7b9358>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=TopKBinaryCrossentropy(k=28),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
